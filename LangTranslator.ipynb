{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, LSTM\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "epochs=10\n",
    "num_samples=10000\n",
    "latent_dim=256 #dimensions\n",
    "data_path='fra.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts=[]\n",
    "target_texts=[]\n",
    "input_char= set()\n",
    "target_char= set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path,'r',encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in lines[: min(num_samples,len(lines)-1)]:\n",
    "    input_text, target_text, _ =line.split('\\t') # separating eng-fre with \\t\n",
    "    \n",
    "    target_text1 = '\\t' + target_text +'\\n'  #adding start \\t and end character \\n in output\n",
    "   \n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text1)\n",
    "    \n",
    "    for char in input_text: #fetching unique input chars\n",
    "        if char not in input_char:\n",
    "            input_char.add(char)\n",
    "            \n",
    "    for char in target_text1: #fetching unique output chars\n",
    "        if char not in target_char: \n",
    "            target_char.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_char=sorted(list(input_char))\n",
    "target_char=sorted(list(target_char))\n",
    "\n",
    "eccharlen=len(input_char) #no of unique input tokens\n",
    "dccharlen=len(target_char) #no of unique output tokens\n",
    "\n",
    "maxslenEC=max([len(txt) for txt in input_texts])  #max seq length for input\n",
    "maxslenDC=max([len(txt) for txt in target_texts]) #max seq length for output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputtokenindex=dict([char,i] for i, char in enumerate(input_char))\n",
    "targettokenindex=dict([char,i] for i, char in enumerate(target_char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST TEXT\n",
    "test=\"Lets go\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputdata=np.zeros((len(input_texts),maxslenEC,eccharlen),dtype='float32')\n",
    "decoder_inputdata=np.zeros((len(target_texts),maxslenDC,dccharlen),dtype='float32')\n",
    "\n",
    "#encode_test=np.zeros((len(test),maxslenEC,eccharlen),dtype='float32')\n",
    "\n",
    "decoder_targetdata=np.zeros((len(target_texts),maxslenDC,dccharlen),dtype='float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#onehot repr.\n",
    "for i,(input_text, target_text) in enumerate(zip(input_texts,target_texts)):\n",
    "    for t, char  in enumerate(input_text):\n",
    "        encoder_inputdata[i, t, inputtokenindex[char]]=1\n",
    "    encoder_inputdata[i, t+1:, inputtokenindex[' ']]=1\n",
    "    \n",
    "    for t, char  in enumerate(target_text):\n",
    "        decoder_inputdata[i, t, targettokenindex[char]]=1\n",
    "        if t>0:\n",
    "            decoder_targetdata[i, t-1, targettokenindex[char]]=1\n",
    "        \n",
    "    decoder_inputdata[i, t+1:, targettokenindex[' ']]=1\n",
    "    decoder_targetdata[i, t:, targettokenindex[' ']]=1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder_inputdata[1]\n",
    "#decoder_inputdata[1]\n",
    "#decoder_targetdata[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder model arch\n",
    "encoder_inputs=Input(shape=(None,eccharlen))\n",
    "encoder= LSTM(latent_dim,return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_states=[state_h,state_c]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoder model arch\n",
    "decoder_inputs=Input(shape=(None,dccharlen))\n",
    "decoder_lstm= LSTM(latent_dim,return_sequences=True ,return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense= Dense(dccharlen, activation='softmax')\n",
    "decoder_outputs= decoder_dense(decoder_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoder_inputs\n",
    "#decoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Model([encoder_inputs,decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit([encoder_inputdata,decoder_inputdata], decoder_targetdata, batch_size=batch_size, epochs=epochs,validation_split=0.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(None, None, 71)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            [(None, None, 94)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   [(None, 256), (None, 335872      input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_8 (LSTM)                   [(None, None, 256),  359424      input_9[0][0]                    \n",
      "                                                                 lstm_7[0][1]                     \n",
      "                                                                 lstm_7[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 94)     24158       lstm_8[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 719,454\n",
      "Trainable params: 719,454\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
